# JMeter-AI 项目说明文档

## 1. 项目简介

本项目是一个基于 **Spring Boot** 和 **大语言模型（LLM）** 的智能接口测试自动化工具。它能够解析 Swagger/OpenAPI 文档，利用 LLM 自动生成结构化的测试用例（JSON），并通过内置的 HTTP 执行器（基于 Curl/OkHttp）完成测试执行，最后由 LLM 对测试结果进行智能分析和总结。

## 2. 核心功能

*   **多模型支持**：支持 DeepSeek、Google Gemini、阿里云 DashScope (通义千问) 等多种 LLM 模型，可通过环境变量灵活切换。
*   **智能生成**：
    *   **Swagger 解析**：自动理解 Swagger JSON 文档结构。
    *   **用例生成**：基于 API 理解生成覆盖基本功能和鉴权的结构化测试用例。
*   **自动化执行**：
    *   **轻量级执行**：不再依赖繁重的 JMeter 引擎，直接生成 HTTP 请求并在内存中执行。
    *   **Curl 兼容**：每个执行记录均包含可复现的 Curl 命令。
*   **智能分析**：测试结束后，LLM 会根据执行结果（成功/失败、耗时、错误信息）生成详细的中文总结报告。
*   **API 驱动**：基于 Spring Boot 开发，提供标准 REST API，易于集成到 CI/CD 或其他平台。

## 3. 技术架构

项目基于 Java 21 和 Spring Boot 3.2.3 开发。

*   **Web 框架**: Spring Boot Web
*   **核心逻辑**: `PipelineService` 串联了 API 理解 -> 用例生成 -> 执行 -> 结果分析的全流程。
*   **LLM 服务**: `LlmService` 封装了不同厂商（DeepSeek, Gemini, DashScope）的适配逻辑。
*   **执行引擎**: `CurlExecutorService` 使用 OkHttp 高效并发执行测试用例。
*   **数据模型**: 统一使用 JSON 结构传递测试用例和结果，解耦了生成与执行。

## 4. 环境配置

项目依赖环境变量进行配置，支持 `.env` 或系统环境变量。

| 环境变量名 | 描述 | 示例值 |
| :--- | :--- | :--- |
| `LLM_PROVIDER` | 指定使用的 LLM 提供商 | `deepseek`, `gemini`, `dashscope` |
| `DEEPSEEK_API_KEY` | DeepSeek API 密钥 | `sk-xxx` |
| `GEMINI_API_KEY` | Google Gemini API 密钥 | `AIzaSy...` |
| `DASHSCOPE_API_KEY`| 阿里云 DashScope API 密钥 | `sk-xxx` |
| `SERVER_PORT` | 服务监听端口 | `8080` (默认) |

**模型配置说明**:
*   **DeepSeek**: 默认使用 `deepseek-chat`。
*   **Gemini**: 默认使用 `gemini-3-pro-preview`。
*   **DashScope**: 默认使用 `qwen-plus`。

## 5. 构建与运行

### 5.1 构建项目

使用 Maven 构建：

```bash
mvn clean package -DskipTests
```

产物位于 `target/jmeter-ai-0.2.0-SNAPSHOT.jar`。

### 5.2 运行服务

```bash
java -jar target/jmeter-ai-0.2.0-SNAPSHOT.jar
```

服务启动后默认监听 8080 端口（或通过 `--server.port=8081` 指定）。

### 5.3 接口调用

**运行测试项目**

`POST /api/project/run`

**请求体 (JSON)**:

```json
{
  "swaggerUrl": "http://localhost:8080/v3/api-docs",
  "programName": "示例项目",
  "extra": "重点测试用户登录和下单流程"
}
```

*   `swaggerUrl`: 目标 API 的 Swagger/OpenAPI 文档地址。
*   `programName`: 项目名称，用于报告生成。
*   `extra`: (可选) 额外的自然语言测试要求。

**响应体 (JSON)**:

返回包含 API 理解、测试用例列表、执行结果详情和最终总结的完整对象。

## 6. 项目结构说明

```
jmeter-test/
├── doc/                        # 文档目录
├── src/main/java/com/example/jmeterai/
│   ├── JMeterAiApplication.java # Spring Boot 启动类
│   ├── controller/             # Web 接口层
│   │   └── JMeterAiController.java
│   ├── service/                # 业务逻辑层
│   │   ├── PipelineService.java    # 主流程
│   │   ├── LlmService.java         # LLM 调用封装
│   │   ├── TestCaseGenerator.java  # 用例生成逻辑
│   │   └── CurlExecutorService.java# HTTP 执行器
│   ├── model/                  # 数据模型
│   │   ├── ProjectResult.java
│   │   ├── TestCase.java
│   │   └── ExecutionResult.java
│   ├── client/                 # LLM 客户端实现
│   └── util/                   # 工具类
├── pom.xml                     # Maven 配置
└── ...
```

## 7. 注意事项

1.  **网络连接**: 确保服务器能访问 LLM API 和目标 Swagger 地址。
2.  **超时设置**: 默认 HTTP 执行超时为 30-60秒，LLM 调用超时为 5-10分钟。
3.  **目标服务**: 测试执行时，目标服务必须是可访问的（Base URL 正确）。如果 Swagger 中的 Server URL 不正确，可能导致测试全失败。
