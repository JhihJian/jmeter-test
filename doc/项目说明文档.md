# JMeter-AI 项目说明文档

## 1. 项目简介

本项目是一个基于 **Spring Boot 3.2** 和 **大语言模型（LLM）** 的智能接口测试自动化工具。它旨在解决传统接口测试中用例编写繁琐、结果校验单一（仅靠状态码）的问题。

项目核心理念是 **"单接口多场景深度测试"**。它能够解析 Swagger/OpenAPI 文档，针对每个接口应用不同的 **质量场景（Quality Scenarios）**（如：快乐路径、参数完整性校验、异常输入测试等），自动生成测试用例并执行。

更重要的是，它引入了 **LLM 智能校验** 机制：测试结果不再仅凭 HTTP 状态码判断成功/失败，而是将请求、响应和接口定义一同回传给 LLM，由 LLM 根据业务逻辑判断测试是否通过。

## 2. 核心功能

*   **多模型支持**：
    *   底层使用 `openai-java` SDK (v0.15.0+)，兼容所有支持 OpenAI 协议的厂商。
    *   已适配 **DeepSeek (深度求索)**、**Google Gemini**、**阿里云 DashScope (通义千问)**。
    *   通过环境变量无缝切换模型提供商。
*   **场景化测试 (Scenario-Based Testing)**：
    *   摒弃粗放的批量生成，采用 **接口粒度** 的测试策略。
    *   针对每个接口，自动遍历预设的 **质量场景**：
        *   `HAPPY_PATH` (快乐路径): 正常业务流程，预期成功。
        *   `PARAM_INTEGRITY` (参数完整性): 缺少必选参数，预期失败。
        *   `ABNORMAL_INPUT` (异常输入): 非法数据格式/边界值，预期失败或报错。
*   **智能校验 (LLM Verification)**：
    *   **语义级断言**：LLM 分析响应体内容。例如：虽然返回 200 OK，但响应体包含 `{"code": 500, "msg": "系统错误"}`，LLM 会判定为测试失败。
    *   **预期行为验证**：如果测试目标是"测试参数缺失"，服务器返回 400 Bad Request，LLM 会判定测试 **通过**（符合预期）。
*   **轻量级执行**：
    *   内置 `CurlExecutorService`，基于 OkHttp 高并发执行。
    *   生成可复现的 Curl 命令，方便开发者手动复核。
*   **结构化报告**：
    *   输出包含用例详情、执行 Curl、响应数据、LLM 校验理由的完整 JSON 报告。
    *   自动生成项目级中文测试总结。

## 3. 技术架构

项目基于 Java 21 和 Spring Boot 3.2.3 开发。

*   **Web 框架**: Spring Boot Web
*   **核心逻辑**: 
    *   `PipelineService`: 核心调度器。负责 "Swagger解析 -> 遍历接口 -> 遍历场景 -> 生成用例 -> 执行用例 -> LLM校验 -> 汇总报告" 的全生命周期。
*   **LLM 服务**: 
    *   `LlmService`: 基于 `com.openai:openai-java` SDK 封装。支持动态配置 Base URL 和 Model，实现 "一次编码，随处调用"。
*   **执行引擎**: 
    *   `CurlExecutorService`: 使用 OkHttp 执行 HTTP 请求，自动处理 Header 和 Body，并记录详细的耗时和状态。
*   **数据模型**: 
    *   `QualityScenario` (Enum): 定义测试场景策略。
    *   `TestCase` / `ExecutionResult`: 结构化的用例和结果对象。
*   **Prompt 管理**:
    *   `PromptPresets`: 集中管理所有与 LLM 交互的提示词（System Prompt / User Prompt），方便调优。

## 4. 环境配置

项目完全通过环境变量配置，支持 `.env` 文件或系统环境变量。

### 基础配置
| 环境变量名 | 描述 | 默认值/示例 |
| :--- | :--- | :--- |
| `SERVER_PORT` | 服务端口 | `8080` |
| `LLM_PROVIDER` | LLM 提供商选择 | `deepseek` / `gemini` / `dashscope` |

### 模型厂商配置

**1. DeepSeek (推荐)**
| 变量名 | 描述 |
| :--- | :--- |
| `DEEPSEEK_API_KEY` | API Key |
| `DEEPSEEK_BASE_URL` | `https://api.deepseek.com` |
| `DEEPSEEK_MODEL` | `deepseek-chat` |

**2. Google Gemini**
| 变量名 | 描述 |
| :--- | :--- |
| `GEMINI_API_KEY` | API Key |
| `GEMINI_BASE_URL` | `https://generativelanguage.googleapis.com/v1beta/openai/` |
| `GEMINI_MODEL` | `gemini-3-pro-preview` |

**3. 阿里云 DashScope**
| 变量名 | 描述 |
| :--- | :--- |
| `DASHSCOPE_API_KEY` | API Key |
| `DASHSCOPE_BASE_URL` | `https://dashscope.aliyuncs.com/compatible-mode/v1` |
| `DASHSCOPE_MODEL` | `qwen-plus` |

## 5. 构建与运行

### 5.1 构建项目

```bash
mvn clean package -DskipTests
```
产物路径: `target/jmeter-ai-0.2.0-SNAPSHOT.jar`

### 5.2 运行服务

```bash
java -jar target/jmeter-ai-0.2.0-SNAPSHOT.jar
```

### 5.3 接口调用 (开始测试)

**接口**: `POST /api/project/run`

**请求体 (JSON)**:
```json
{
  "swaggerUrl": "http://localhost:8080/v3/api-docs",
  "programName": "电商后台管理系统",
  "extra": "重点测试订单创建接口的幂等性"
}
```

**响应体**:
返回一个包含 `ProjectResult` 的大 JSON 对象，其中 `executionResults` 字段包含每个用例的详细执行与校验信息。

## 6. 项目结构说明

```
jmeter-test/
├── doc/                        # 文档
├── src/main/java/com/example/jmeterai/
│   ├── JMeterAiApplication.java
│   ├── controller/
│   │   └── JMeterAiController.java  # 入口 API
│   ├── service/
│   │   ├── PipelineService.java     # [核心] 测试流程编排
│   │   ├── LlmService.java          # LLM SDK 封装
│   │   ├── CurlExecutorService.java # HTTP 请求执行
│   │   └── TestCaseGenerator.java   # 用例解析逻辑
│   ├── model/
│   │   ├── QualityScenario.java     # [新] 质量场景枚举
│   │   ├── TestCase.java            # 用例定义
│   │   ├── ExecutionResult.java     # 执行与校验结果
│   │   └── ...
│   └── util/
│       ├── OpenApiExtractor.java    # Swagger 解析
│       ├── PromptPresets.java       # [核心] 提示词库
│       └── ...
└── pom.xml
```

## 7. 维护指南

### 如何添加新的测试场景？
1.  修改 `model/QualityScenario.java`，添加新的枚举值（例如 `SECURITY_SQL_INJECTION`）。
2.  修改 `util/PromptPresets.java` 中的 `singleInterfaceUserPrompt` 方法，在提示词中告知 LLM 该场景的生成规则。
3.  重新编译运行，系统会自动在遍历时包含新场景。

### 如何调整 LLM 校验逻辑？
1.  修改 `util/PromptPresets.java` 中的 `verificationUserPrompt`。
2.  可以调整判断标准（例如：是否允许 500 错误，是否校验特定的 Error Code）。

### 日志排查
项目集成了详细的日志输出：
*   **INFO**: 关注测试进度 (Endpoint [x/y])、场景切换、用例执行结果 (PASS/FAIL)。
*   **DEBUG**: 开启 Debug 级别可查看完整的 LLM 请求/响应内容、生成的 Curl 命令细节。
